"""
Example 1:


Example 2:

"""

input_ids = [0, 1640, 3480, 4839, 286, 5, 78, 86, 11, 799,
             107, 2156, 10, 1012, 7875, 1835, 7, 608, 99, 37,
             473, 275, 479, 646, 3388, 510, 1215, 288, 742, 17657,
             47385, 3277, 174, 7, 22, 283, 15, 159, 27785, 22,
             15, 5, 587, 112, 5403, 9, 22, 20, 3655, 1534,
             5143, 22, 13590, 45, 1482, 8238, 13179, 53, 277, 2950,
             652, 11, 1427, 9, 5, 7069, 479, 646, 3388, 510,
             1215, 134, 742, 2978, 2156, 89, 21, 3045, 21998, 2156,
             54, 4457, 5, 1012, 177, 311, 13, 1718, 107, 137,
             8296, 159, 11, 3010, 479, 646, 3388, 510, 1215, 176,
             742, 7817, 579, 47385, 642, 47385, 1506, 23, 8301, 2156,
             21998, 7521, 5, 78, 425, 111, 24224, 177, 9, 5,
             311, 2156, 5, 4187, 22, 20088, 7732, 2156, 22, 137,
             3408, 5162, 5941, 81, 7, 13179, 2156, 54, 1550, 62,
             479, 646, 3388, 510, 1215, 246, 742, 2285, 145, 409,
             31, 5, 311, 13, 144, 9, 5, 375, 799, 107,
             2156, 21998, 399, 128, 326, 2045, 7, 2649, 10, 1451,
             479, 2]

alpha = [0.0031795501708984375, 0.00832366943359375, 0.0014619827270507812, 0.004566192626953125, 0.015869140625,
         0.004268646240234375, 0.00799560546875, 0.004039764404296875, 0.0020198822021484375, 0.0016908645629882812,
         0.0025081634521484375, 0.0009126663208007812, 0.0019893646240234375, 0.00550079345703125, 0.004436492919921875,
         0.00293731689453125, 0.002162933349609375, 0.003231048583984375, 0.0013799667358398438, 0.0008697509765625,
         0.0035037994384765625, 0.005931854248046875, 0.0027332305908203125, 0.0008187294006347656, 0.0125274658203125,
         0.00232696533203125, 0.002346038818359375, 0.004322052001953125, 0.0035800933837890625, 0.0037822723388671875,
         0.01067352294921875, 0.0037670135498046875, 0.01082611083984375, 0.01666259765625, 0.001865386962890625,
         0.00434112548828125, 0.006671905517578125, 0.0074462890625, 0.0003857612609863281, 0.0004153251647949219,
         0.0052032470703125, 0.007678985595703125, 0.005222320556640625, 0.005954742431640625, 0.0026607513427734375,
         0.000732421875, 0.000286102294921875, 0.0017538070678710938, 0.0008673667907714844, 0.0004661083221435547,
         0.00023949146270751953, 0.0005674362182617188, 0.0138397216796875, 0.01413726806640625, 0.005115509033203125,
         0.01204681396484375, 0.0025272369384765625, 0.006237030029296875, 0.00263214111328125, 0.0011262893676757812,
         0.0034122467041015625, 0.005062103271484375, 0.016510009765625, 0.01116180419921875, 0.004924774169921875,
         0.0003972053527832031, 0.0029659271240234375, 0.0009450912475585938, 0.0157623291015625, 0.0024852752685546875,
         0.0018320083618164062, 0.00316619873046875, 0.0007638931274414062, 0.00458526611328125, 0.0009603500366210938,
         0.002391815185546875, 0.0024738311767578125, 0.00186920166015625, 0.0006661415100097656, 0.00106048583984375,
         0.001750946044921875, 0.0029506683349609375, 0.0007586479187011719, 0.0034656524658203125,
         0.0007500648498535156, 0.0008573532104492188, 0.0015974044799804688, 0.00078582763671875, 0.000705718994140625,
         0.0025653839111328125, 0.0038738250732421875, 0.0048980712890625, 0.0028514862060546875, 0.0010385513305664062,
         0.0027179718017578125, 0.0011072158813476562, 0.00891876220703125, 0.0016069412231445312,
         0.0015592575073242188, 0.005584716796875, 0.0020198822021484375, 0.0069122314453125, 0.0224151611328125,
         0.00726318359375, 0.00586700439453125, 0.006877899169921875, 0.00543975830078125, 0.0028533935546875,
         0.0030994415283203125, 0.004184722900390625, 0.004001617431640625, 0.01363372802734375, 0.00405120849609375,
         0.005588531494140625, 0.00792694091796875, 0.01294708251953125, 0.0299224853515625, 0.0011472702026367188,
         0.00162506103515625, 0.0029621124267578125, 0.0019168853759765625, 0.0015850067138671875,
         0.0020427703857421875, 0.003032684326171875, 0.0008373260498046875, 0.0013885498046875, 0.0034236907958984375,
         0.0006351470947265625, 0.00048279762268066406, 0.01136016845703125, 0.025146484375, 0.01059722900390625,
         0.01200103759765625, 0.01326751708984375, 0.00888824462890625, 0.00200653076171875, 0.0022716522216796875,
         0.005954742431640625, 0.0014600753784179688, 0.002254486083984375, 0.0037326812744140625,
         0.0009479522705078125, 0.01496124267578125, 0.0029964447021484375, 0.0017271041870117188,
         0.0021800994873046875, 0.0009751319885253906, 0.00846099853515625, 0.00766754150390625, 0.00397491455078125,
         0.0030345916748046875, 0.00447845458984375, 0.0021266937255859375, 0.0123748779296875, 0.0037097930908203125,
         0.00533294677734375, 0.002681732177734375, 0.0017261505126953125, 0.0017986297607421875, 0.0033588409423828125,
         0.0019550323486328125, 0.0026378631591796875, 0.029754638671875, 0.04473876953125, 0.062744140625,
         0.031494140625, 0.01126861572265625, 0.01105499267578125, 0.0189971923828125, 0.01666259765625,
         0.00498199462890625, 0.006877899169921875]

index = [i for i in range(len(alpha))]
normalized_alpha = [(num - min(alpha)) / (max(alpha) - min(alpha)) for num in alpha]

from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("sshleifer/distilbart-cnn-12-6")
token = [tokenizer.decode(s) for s in input_ids]

import pandas as pd

df = pd.DataFrame({'topic': normalized_alpha, 'index': index, 'token': token})

sorted_df = df.sort_values('topic', ascending=False)

print(list(sorted_df['token'][:20]))

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# results = np.random.rand(4, 3)
# strings = strings = np.asarray([['a', 'b', 'c'],
#                                 ['d', 'e', 'f'],
#                                 ['g', 'h', 'i'],
#                                 ['j', 'k', 'l']])


# results = np.asarray([normalized_alpha]).reshape(43,4)
# strings = np.asarray([token]).reshape(43,4)
#
# labels = (np.asarray(["{0}".format(string)
#                       for string in zip(strings.flatten())])).reshape(43,4)
#
#
# fig, ax = plt.subplots()
# sns.heatmap(results, annot=labels, fmt="", cmap='RdYlGn', ax=ax)
# plt.show()

f = open("/Users/rachelzheng/Downloads/attention.txt", "r")
l = []
for line in f:
    l.append(line.replace('\n', ''))

a = [item.split(" ") for item in l]

b = []
for i in range(len(a)):
    b.append([float(num) for num in a[i]])

import numpy as np
c = []
for line in b:
    c.append(np.sum(line))

normalized_c = [(num-min(c))/(max(c)-min(c)) for num in c]

results = np.asarray([normalized_c]).reshape(43,4)
strings = np.asarray([token]).reshape(43,4)

labels = (np.asarray(["{0}".format(string)
                      for string in zip(strings.flatten())])).reshape(43,4)

fig, ax = plt.subplots()
sns.heatmap(results, annot=labels, fmt="", cmap='RdYlGn', ax=ax)
plt.show()